{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna AllenNLP Custom Loop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdsdYSAPHk/l1horfomMme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himkt/optuna-allennlp/blob/master/Optuna_AllenNLP_Custom_Loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6pVEnVBttn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --quiet \"allennlp==v1.1.0rc3\" optuna plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kooGmC1a1_Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "from allennlp.data import Vocabulary, allennlp_collate\n",
        "from allennlp.data.dataset_readers import TextClassificationJsonReader\n",
        "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers import WhitespaceTokenizer\n",
        "from allennlp.models import BasicClassifier\n",
        "from allennlp.modules import Embedding\n",
        "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.training import GradientDescentTrainer\n",
        "import numpy\n",
        "import optuna\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from optuna.integration import AllenNLPPruningCallback\n",
        "from optuna import Trial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2QUP8_N2FQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data():\n",
        "    reader = TextClassificationJsonReader(\n",
        "        token_indexers={\"tokens\": SingleIdTokenIndexer()},\n",
        "        tokenizer=WhitespaceTokenizer(),\n",
        "    )\n",
        "    train_dataset = reader.read(\"https://s3-us-west-2.amazonaws.com/allennlp/datasets/imdb/train.jsonl\")  # NOQA\n",
        "    valid_dataset = reader.read(\"https://s3-us-west-2.amazonaws.com/allennlp/datasets/imdb/dev.jsonl\")  # NOQA\n",
        "    vocab = Vocabulary.from_instances(train_dataset)\n",
        "    train_dataset.index_with(vocab)\n",
        "    valid_dataset.index_with(vocab)\n",
        "    return train_dataset, valid_dataset, vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09YvXjXI2I6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(\n",
        "        vocab: Vocabulary,\n",
        "        embedding_dim: int,\n",
        "        max_filter_size: int,\n",
        "        num_filters: int,\n",
        "        output_dim: int,\n",
        "        dropout: float,\n",
        "):\n",
        "    model = BasicClassifier(\n",
        "        text_field_embedder=BasicTextFieldEmbedder(\n",
        "            {\n",
        "                \"tokens\": Embedding(\n",
        "                  embedding_dim=embedding_dim,\n",
        "                  trainable=True,\n",
        "                  vocab=vocab\n",
        "              )\n",
        "            }\n",
        "        ),\n",
        "        seq2vec_encoder=CnnEncoder(\n",
        "            ngram_filter_sizes=range(2, max_filter_size),\n",
        "            num_filters=num_filters,\n",
        "            embedding_dim=embedding_dim,\n",
        "            output_dim=output_dim,\n",
        "        ),\n",
        "        dropout=dropout,\n",
        "        vocab=vocab,\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxODxVjU2LhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial: Trial):\n",
        "    embedding_dim = trial.suggest_int(\"embedding_dim\", 128, 256)\n",
        "    max_filter_size = trial.suggest_int(\"max_filter_size\", 3, 6)\n",
        "    num_filters = trial.suggest_int(\"num_filters\", 128, 256)\n",
        "    output_dim = trial.suggest_int(\"output_dim\", 128, 512)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0, 1.0)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
        "\n",
        "    train_dataset, valid_dataset, vocab = prepare_data()\n",
        "    model = build_model(vocab, embedding_dim, max_filter_size, num_filters, output_dim, dropout)\n",
        "    model.to(torch.device(\"cuda:0\"))\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=lr)\n",
        "    data_loader = DataLoader(train_dataset, batch_size=10, collate_fn=allennlp_collate)\n",
        "    validation_data_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=allennlp_collate)\n",
        "    trainer = GradientDescentTrainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=data_loader,\n",
        "        validation_data_loader=validation_data_loader,\n",
        "        validation_metric=\"+accuracy\",\n",
        "        patience=None,  # `patience=None` since it could conflict with AllenNLPPruningCallback\n",
        "        num_epochs=10,\n",
        "        serialization_dir=f\"result/{trial.number}\",\n",
        "        epoch_callbacks=[AllenNLPPruningCallback(trial, \"validation_accuracy\")],\n",
        "    )\n",
        "    return trainer.train()[\"best_validation_accuracy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q14wrX0I2OX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(41)\n",
        "torch.manual_seed(41)\n",
        "numpy.random.seed(41)\n",
        "\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        ")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RsHeYY18mFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "study.trials_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlCI8hCO8qR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqfDUFDi8snd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optuna.visualization.plot_param_importances(study)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}